{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.imports import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # so the IDs match nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\" # \"0, 1\" for multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import calc_mean_std_par_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = '../data/SRAD2018_TRAIN_001/RAD_206482464212530/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_dir = Path('../data/SRAD2018_TRAIN_001')\n",
    "subdirs = [o for o in par_dir.iterdir() if o.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "means, stds = zip(*[calc_mean_std_subdir(o) for o in subdirs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.9820557,\n",
       "  0.7564683,\n",
       "  0.968596,\n",
       "  0.9650422,\n",
       "  0.98231244,\n",
       "  0.7932429,\n",
       "  0.9655625,\n",
       "  0.97146374,\n",
       "  0.9070648,\n",
       "  0.7613075),\n",
       " (0.12885971,\n",
       "  0.3993739,\n",
       "  0.16909033,\n",
       "  0.17655694,\n",
       "  0.12847538,\n",
       "  0.39483172,\n",
       "  0.17846707,\n",
       "  0.16026804,\n",
       "  0.28292444,\n",
       "  0.41495243))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8c493eb7a40b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stds' is not defined"
     ]
    }
   ],
   "source": [
    "mean , std = np.mean(stds), np.mean(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e4c77e75174a2ba84760b2a30eeb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-abd73139dedd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_mean_std_par_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/SRAD2018_TRAIN_002'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/pred-rain/yang/data_reader.py\u001b[0m in \u001b[0;36mcalc_mean_std_par_dir\u001b[0;34m(par_dir)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcalc_mean_std_subdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pred-rain/yang/data_reader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcalc_mean_std_subdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pred-rain/yang/data_reader.py\u001b[0m in \u001b[0;36mcalc_mean_std_subdir\u001b[0;34m(subdir)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \"\"\"\n\u001b[1;32m     45\u001b[0m     \u001b[0mims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopen_greyscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2920\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mean, std = calc_mean_std_par_dir('../data/SRAD2018_TRAIN_002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'stat.csv'\n",
    "with open(fn, 'w') as f:\n",
    "        np.array([mean, std]).tofile(f, ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27102503180503845,0.8787143230438232"
     ]
    }
   ],
   "source": [
    "!cat stat.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SequenceGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (61, 501, 501, 3)\n",
    "def parser_train(serialized_example):\n",
    "    features, sequence_features = tf.parse_single_sequence_example(\n",
    "        serialized_example, context_features={\n",
    "            'time_stamp': tf.FixedLenFeature([], tf.string),\n",
    "        }, sequence_features={\n",
    "            \"raw_png\": tf.FixedLenSequenceFeature([], dtype=tf.string)\n",
    "        })\n",
    "    \n",
    "    x = tf.map_fn(tf.image.decode_png, sequence_features['raw_png'], dtype=tf.uint8,\n",
    "                back_prop=False, swap_memory=False, infer_shape=False)\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x /= 255\n",
    "    x.set_shape(shape)\n",
    "    x = tf.expand_dims(x[:,:,:,0], axis=3)\n",
    "    \n",
    "    return x, features['time_stamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<utils.transforms.Scale object at 0x7fb8c2839b38>, <__main__.Slice object at 0x7fb8c2823748>, <utils.transforms.Normalize object at 0x7fb8c28236d8>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.transforms import *\n",
    "\n",
    "sz = 128\n",
    "nt = 10\n",
    "stats = np.fromfile('stat.csv', sep=',')\n",
    "\n",
    "class Slice(Transform):\n",
    "    \"\"\" Return a slice of the images\n",
    "    \n",
    "    Arguments:\n",
    "    The same as the built-in function slice\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.slice = slice(*args, **kwargs)\n",
    "        super().__init__(TfmType.NO)\n",
    "        \n",
    "    def do_transform(self, x, is_y):\n",
    "        return x[self.slice]\n",
    "    \n",
    "aug_tfms = [Slice(nt)]\n",
    "tfms, _ = tfms_from_stats(stats, sz, aug_tfms=aug_tfms, crop_type=CropType.NO)\n",
    "tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bs = 10\n",
    "\n",
    "filenames = tf.placeholder(tf.string, name='tfrecords')\n",
    "training_filenames = '../data/tfrecords/train_1.tfrecords'\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(parser_train).map(tfms).batch(bs).repeat()\n",
    "# dataset = dataset.prefetch()\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "iterator.initializer.run({filenames: training_filenames})\n",
    "x, time_stamp = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring PredNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('All cells must have a `call` method. received cells:', (1, 48, 96, 192))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4f7676b26b2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                   \u001b[0mA_filt_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                   \u001b[0mAhat_filt_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                   R_filt_sizes)\n\u001b[0m",
      "\u001b[0;32m~/pred-rain/yang/models/prednet_refactored.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cell, return_sequences, return_state, go_backwards, stateful, unroll, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m                         \u001b[0mgo_backwards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgo_backwards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                         \u001b[0mstateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                         unroll=unroll,)\n\u001b[0m\u001b[1;32m    361\u001b[0m                         \u001b[0;31m# **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cell, return_sequences, return_state, go_backwards, stateful, unroll, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m                **kwargs):\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackedRNNCells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m       raise ValueError('`cell` should have a `call` method. '\n",
      "\u001b[0;32m~/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cells, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         raise ValueError('All cells must have a `call` method. '\n\u001b[0;32m---> 70\u001b[0;31m                          'received cells:', cells)\n\u001b[0m\u001b[1;32m     71\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state_size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         raise ValueError('All cells must have a '\n",
      "\u001b[0;31mValueError\u001b[0m: ('All cells must have a `call` method. received cells:', (1, 48, 96, 192))"
     ]
    }
   ],
   "source": [
    "from models.prednet_refactored import PredNetCell, PredNet\n",
    "\n",
    "# n_channels, im_height, im_width = (3, 128, 160)\n",
    "n_channels, im_height, im_width = (1, sz, sz)\n",
    "input_shape = (im_height, im_width, n_channels)\n",
    "stack_sizes = (n_channels, 48, 96, 192)\n",
    "R_stack_sizes = stack_sizes\n",
    "A_filt_sizes = (3, 3, 3)\n",
    "Ahat_filt_sizes = (3, 3, 3, 3)\n",
    "R_filt_sizes = (3, 3, 3, 3)\n",
    "\n",
    "layer_loss_weights = np.array([1., 0., 0., 0.])  # weighting for each layer in final loss; \"L_0\" model:  [1, 0, 0, 0], \"L_all\": [1, 0.1, 0.1, 0.1]\n",
    "layer_loss_weights = np.expand_dims(layer_loss_weights, 1)\n",
    "time_loss_weights = 1./ (nt - 1) * np.ones((nt,1))  # equally weight all timesteps except the first\n",
    "time_loss_weights[0] = 0\n",
    "\n",
    "prednet = PredNet(stack_sizes,\n",
    "                  R_stack_sizes,\n",
    "                  A_filt_sizes, \n",
    "                  Ahat_filt_sizes, \n",
    "                  R_filt_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# inputs = tf.keras.layers.Input(shape=(nt,) + input_shape)\n",
    "errors = prednet(x)  # errors will be (batch_size, nt, nb_layers)\n",
    "# errors = prednet(x[0][0])  # errors will be (batch_size, nt, nb_layers)\n",
    "errors_by_time = TimeDistributed(Dense(1, trainable=False), weights=[layer_loss_weights, np.zeros(1)], trainable=False)(errors)  # calculate weighted error by layer\n",
    "errors_by_time = Flatten()(errors_by_time)  # will be (batch_size, nt)\n",
    "final_errors = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False)(errors_by_time)  # weight errors by time\n",
    "model = Model(inputs=inputs, outputs=final_errors)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 64s 6s/step - loss: 0.3643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5c911c8240>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.transforms import *\n",
    "sz = 128\n",
    "nt = 10\n",
    "bs = 4\n",
    "\n",
    "num_gpus = 2\n",
    "\n",
    "class Slice(Transform):\n",
    "    \"\"\" Return a slice of the images\n",
    "    \n",
    "    Arguments:\n",
    "    The same as the built-in function slice\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.slice = slice(*args, **kwargs)\n",
    "        super().__init__(TfmType.NO)\n",
    "        \n",
    "    def do_transform(self, x, is_y):\n",
    "        return x[self.slice]\n",
    "\n",
    "aug_tfms = [Slice(nt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(sz=128, nt=10, aug_tfms=aug_tfms,\n",
    "             stats_fn='stat.csv', stats_sep=','):\n",
    "    shape = (61, 501, 501, 3)\n",
    "    def parser_train(serialized_example):\n",
    "        features, sequence_features = tf.parse_single_sequence_example(\n",
    "            serialized_example, context_features={\n",
    "                'time_stamp': tf.FixedLenFeature([], tf.string),\n",
    "            }, sequence_features={\n",
    "                \"raw_png\": tf.FixedLenSequenceFeature([], dtype=tf.string)\n",
    "            })\n",
    "\n",
    "        x = tf.map_fn(tf.image.decode_png, sequence_features['raw_png'], dtype=tf.uint8,\n",
    "                    back_prop=False, swap_memory=False, infer_shape=False)\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x /= 255\n",
    "        x.set_shape(shape)\n",
    "        x = tf.expand_dims(x[:,:,:,0], axis=3)\n",
    "\n",
    "        return x, features['time_stamp']\n",
    "    \n",
    "    filenames = tf.placeholder(tf.string, name='tfrecords')\n",
    "    \n",
    "    stats = np.fromfile(stats_fn, sep=stats_sep)\n",
    "    tfms, _ = tfms_from_stats(stats, sz, aug_tfms=aug_tfms, crop_type=CropType.NO)\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(parser_train).map(tfms).batch(bs).repeat()\n",
    "    # dataset = dataset.prefetch()\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.prednet_refactored import PredNetCell, PredNet\n",
    "\n",
    "# n_channels, im_height, im_width = (3, 128, 160)\n",
    "n_channels, im_height, im_width = (1, sz, sz)\n",
    "input_shape = (im_height, im_width, n_channels)\n",
    "stack_sizes = (n_channels, 48, 96, 192)\n",
    "R_stack_sizes = stack_sizes\n",
    "A_filt_sizes = (3, 3, 3)\n",
    "Ahat_filt_sizes = (3, 3, 3, 3)\n",
    "R_filt_sizes = (3, 3, 3, 3)\n",
    "\n",
    "layer_loss_weights = np.array([1., 0., 0., 0.])  # weighting for each layer in final loss; \"L_0\" model:  [1, 0, 0, 0], \"L_all\": [1, 0.1, 0.1, 0.1]\n",
    "layer_loss_weights = np.expand_dims(layer_loss_weights, 1)\n",
    "time_loss_weights = 1./ (nt - 1) * np.ones((nt,1))  # equally weight all timesteps except the first\n",
    "time_loss_weights[0] = 0\n",
    "\n",
    "prednet_cell = PredNetCell(stack_sizes=stack_sizes,\n",
    "                    R_stack_sizes=R_stack_sizes,\n",
    "                    A_filt_sizes=A_filt_sizes,\n",
    "                    Ahat_filt_sizes=Ahat_filt_sizes,\n",
    "                    R_filt_sizes=R_filt_sizes)\n",
    "\n",
    "prednet = PredNet(prednet_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(nt,) + input_shape)\n",
    "errors = prednet(inputs)  # errors will be (batch_size, nt, nb_layers)\n",
    "errors_by_time = TimeDistributed(Dense(1, trainable=False), weights=[layer_loss_weights, np.zeros(1)], trainable=False)(errors)  # calculate weighted error by layer\n",
    "errors_by_time = Flatten()(errors_by_time)  # will be (batch_size, nt)\n",
    "final_errors = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False)(errors_by_time)  # weight errors by time\n",
    "model = Model(inputs=inputs, outputs=final_errors)\n",
    "# model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "# model = tf.keras.utils.multi_gpu_model(model, gpus=num_gpus)\n",
    "# model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "model.compile(loss='mean_absolute_error', optimizer=tf.train.AdamOptimizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 128, 128, 1)   0         \n",
      "_________________________________________________________________\n",
      "pred_net (PredNet)           (None, 10, 4)             6909818   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 10, 1)             5         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 6,909,834\n",
      "Trainable params: 6,909,818\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(fns = ['../data/tfrecords/train_1.tfrecords'],\n",
    "             sz=128, nt=10, aug_tfms=aug_tfms,\n",
    "             stats_fn='stat.csv', stats_sep=','):\n",
    "    dataset = tf.data.TFRecordDataset(fns)\n",
    "    \n",
    "    y = tf.zeros([bs, 1])\n",
    "    def parser_train(serialized_example):\n",
    "        # experimental. TODO: read only needed samples\n",
    "        shape = (61, 501, 501, 3)\n",
    "        context_features = {\n",
    "                'time_stamp': tf.FixedLenFeature([], tf.string),\n",
    "            }\n",
    "        sequence_features = {\n",
    "                \"raw_png\": tf.FixedLenSequenceFeature([], dtype=tf.string)\n",
    "            }\n",
    "        \n",
    "        features, sequence_features = tf.parse_single_sequence_example(\n",
    "            serialized_example, \n",
    "            context_features=context_features, \n",
    "            sequence_features=sequence_features)\n",
    "\n",
    "        x = tf.map_fn(tf.image.decode_png, sequence_features['raw_png'], dtype=tf.uint8,\n",
    "                    back_prop=False, swap_memory=False, infer_shape=False)\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x /= 255\n",
    "        x.set_shape(shape)\n",
    "        x = tf.expand_dims(x[:,:,:,0], axis=3)\n",
    "        return x, y\n",
    "    \n",
    "    stats = np.fromfile(stats_fn, sep=stats_sep)\n",
    "    tfms, _ = tfms_from_stats(stats, sz, aug_tfms=aug_tfms, crop_type=CropType.NO)\n",
    "    \n",
    "    dataset = dataset.map(parser_train)\n",
    "    dataset = dataset.map(tfms)\n",
    "    dataset = dataset.batch(bs)\n",
    "    dataset = dataset.repeat()\n",
    "    # dataset = dataset.prefetch()\n",
    "    \n",
    "#     return dataset\n",
    "    \n",
    "    y = tf.zeros([bs, 1])\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    x, _ = iterator.get_next()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "??keras.callbacks.TensorBoard(write_grads=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(write_grads=True, write_images=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 7s 723ms/step - loss: 0.1705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6dfc3ef518>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, steps_per_epoch=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 444ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.28812453150749207"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x, y, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {'PredNetCell': PredNetCell, 'PredNet': PredNet}\n",
    "model = tf.keras.models.load_model('keras', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to estimator to leverage multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple gpus\n",
    "strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=2)\n",
    "session_config = tf.ConfigProto(log_device_placement=True, \n",
    "                                allow_soft_placement=True)\n",
    "session_config.gpu_options.allow_growth = True\n",
    "config = tf.estimator.RunConfig(train_distribute=strategy, session_config=session_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '../data/models', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "log_device_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7efa66e380f0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efa65c59e10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "with tf.keras.utils.CustomObjectScope({'PredNetCell': PredNetCell, 'PredNet': PredNet}):\n",
    "#     with tf.device('/gpu:0'):\n",
    "    keras_estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir='../data/models', config=config)\n",
    "#     keras_estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir='../data/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(fns = ['../data/tfrecords/train_1.tfrecords'],\n",
    "             sz=128, nt=10, aug_tfms=aug_tfms,\n",
    "             stats_fn='stat.csv', stats_sep=','):\n",
    "    dataset = tf.data.TFRecordDataset(fns)\n",
    "    \n",
    "    y = tf.zeros([bs, 1])\n",
    "    def parser_train(serialized_example):\n",
    "        # experimental. TODO: read only needed samples\n",
    "        shape = (61, 501, 501, 3)\n",
    "        context_features = {\n",
    "                'time_stamp': tf.FixedLenFeature([], tf.string),\n",
    "            }\n",
    "        sequence_features = {\n",
    "                \"raw_png\": tf.FixedLenSequenceFeature([], dtype=tf.string)\n",
    "            }\n",
    "        \n",
    "        features, sequence_features = tf.parse_single_sequence_example(\n",
    "            serialized_example, \n",
    "            context_features=context_features, \n",
    "            sequence_features=sequence_features)\n",
    "\n",
    "        x = tf.map_fn(tf.image.decode_png, sequence_features['raw_png'], dtype=tf.uint8,\n",
    "                    back_prop=False, swap_memory=False, infer_shape=False)\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x /= 255\n",
    "        x.set_shape(shape)\n",
    "        x = tf.expand_dims(x[:,:,:,0], axis=3)\n",
    "        return x, y\n",
    "    \n",
    "    stats = np.fromfile(stats_fn, sep=stats_sep)\n",
    "    tfms, _ = tfms_from_stats(stats, sz, aug_tfms=aug_tfms, crop_type=CropType.NO)\n",
    "    \n",
    "    dataset = dataset.map(parser_train)\n",
    "    dataset = dataset.map(tfms)\n",
    "    dataset = dataset.batch(bs)\n",
    "    dataset = dataset.repeat()\n",
    "    # dataset = dataset.prefetch()\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "    y = tf.zeros([bs, 1])\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    x, _ = iterator.get_next()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\n",
      "INFO:tensorflow:Configured nccl all-reduce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of tensorflow.python.keras.layers.core failed: Traceback (most recent call last):\n",
      "  File \"/home/ywx/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ywx/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 368, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ywx/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/ywx/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/importlib/__init__.py\", line 147, in reload\n",
      "    raise ImportError(msg.format(name), name=name)\n",
      "ImportError: module tensorflow.python.keras.utils.multi_gpu_utils not in sys.modules\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 46 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='../data/models/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('../data/models/keras/keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_a_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_a_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_a_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_a_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_a_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_a_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_ahat_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_ahat_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_ahat_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_ahat_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_ahat_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_ahat_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_ahat_3/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_ahat_3/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_c_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_c_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_c_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_c_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_c_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_c_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_c_3/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_c_3/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_f_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_f_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_f_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_f_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_f_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_f_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_f_3/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_f_3/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_i_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_i_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_i_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_i_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_i_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_i_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_i_3/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_i_3/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_o_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_o_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_o_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_o_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_o_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_o_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_o_3/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/layer_o_3/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/Variable; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/Variable_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/Variable_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/Variable_3; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/Variable_4; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/Variable_5; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/Variable_6; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/Variable_7; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/Variable_8; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/Variable_9; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/Variable_10; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: pred_net/Variable_11; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2/pred_net/Variable; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2/pred_net/Variable_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2/pred_net/Variable_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2/pred_net/Variable_3; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2/pred_net/Variable_4; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2/pred_net/Variable_5; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2/pred_net/Variable_6; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2/pred_net/Variable_7; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2/pred_net/Variable_8; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2/pred_net/Variable_9; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2/pred_net/Variable_10; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2/pred_net/Variable_11; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2_1/pred_net/Variable; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2_1/pred_net/Variable_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2_1/pred_net/Variable_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2_1/pred_net/Variable_3; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2_1/pred_net/Variable_4; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2_1/pred_net/Variable_5; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2_1/pred_net/Variable_6; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2_1/pred_net/Variable_7; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2_1/pred_net/Variable_8; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2_1/pred_net/Variable_9; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2_1/pred_net/Variable_10; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: model_2_1/pred_net/Variable_11; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: tower_1/pred_net_1/Variable; prev_var_name: Unchanged\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor tower_1/pred_net_1/Variable is not found in ../data/models/keras/keras_model.ckpt checkpoint {'training/TFOptimizer/beta2_power': [], 'training/TFOptimizer/beta1_power': [], 'time_distributed_2/kernel': [4, 1], 'pred_net/layer_o_3/kernel/Adam_1': [3, 3, 576, 192], 'pred_net/layer_o_3/kernel/Adam': [3, 3, 576, 192], 'pred_net/layer_o_3/bias/Adam_1': [192], 'pred_net/layer_o_3/bias/Adam': [192], 'pred_net/layer_o_2/kernel/Adam_1': [3, 3, 480, 96], 'pred_net/layer_o_2/bias/Adam_1': [96], 'pred_net/layer_o_1/kernel/Adam_1': [3, 3, 240, 48], 'pred_net/layer_o_1/kernel': [3, 3, 240, 48], 'pred_net/layer_o_1/bias/Adam': [48], 'pred_net/layer_o_0/kernel': [3, 3, 51, 1], 'pred_net/layer_o_0/bias': [1], 'pred_net/layer_i_3/bias/Adam_1': [192], 'pred_net/layer_o_2/bias/Adam': [96], 'pred_net/layer_i_3/bias': [192], 'pred_net/layer_i_2/kernel/Adam': [3, 3, 480, 96], 'pred_net/layer_i_2/kernel': [3, 3, 480, 96], 'pred_net/layer_i_2/bias': [96], 'pred_net/layer_i_1/kernel/Adam_1': [3, 3, 240, 48], 'pred_net/layer_i_1/kernel': [3, 3, 240, 48], 'pred_net/layer_i_1/bias/Adam_1': [48], 'pred_net/layer_i_1/bias/Adam': [48], 'pred_net/layer_i_1/bias': [48], 'pred_net/layer_i_0/kernel/Adam_1': [3, 3, 51, 1], 'pred_net/layer_i_3/bias/Adam': [192], 'pred_net/layer_i_0/kernel': [3, 3, 51, 1], 'pred_net/layer_i_0/bias/Adam_1': [1], 'pred_net/layer_i_0/bias': [1], 'pred_net/layer_o_0/bias/Adam_1': [1], 'pred_net/layer_f_3/bias/Adam_1': [192], 'pred_net/layer_f_3/bias': [192], 'pred_net/layer_f_2/kernel/Adam': [3, 3, 480, 96], 'pred_net/layer_f_2/bias/Adam_1': [96], 'pred_net/layer_f_2/bias/Adam': [96], 'pred_net/layer_f_2/bias': [96], 'pred_net/layer_f_3/kernel/Adam_1': [3, 3, 576, 192], 'pred_net/layer_f_1/kernel/Adam': [3, 3, 240, 48], 'pred_net/layer_f_1/bias/Adam_1': [48], 'pred_net/layer_f_0/kernel/Adam': [3, 3, 51, 1], 'pred_net/layer_f_0/bias/Adam': [1], 'pred_net/layer_f_0/bias': [1], 'pred_net/layer_i_0/bias/Adam': [1], 'pred_net/layer_c_3/kernel/Adam_1': [3, 3, 576, 192], 'pred_net/layer_c_3/bias/Adam_1': [192], 'pred_net/layer_c_3/bias/Adam': [192], 'pred_net/layer_c_3/bias': [192], 'pred_net/layer_c_2/kernel/Adam_1': [3, 3, 480, 96], 'pred_net/layer_c_2/kernel/Adam': [3, 3, 480, 96], 'pred_net/layer_f_0/kernel/Adam_1': [3, 3, 51, 1], 'pred_net/layer_c_2/kernel': [3, 3, 480, 96], 'pred_net/layer_f_3/bias/Adam': [192], 'pred_net/layer_a_0/kernel/Adam': [3, 3, 2, 48], 'pred_net/layer_a_0/kernel': [3, 3, 2, 48], 'time_distributed_2/bias': [1], 'pred_net/Variable_4': [1, 16384], 'pred_net/layer_c_0/bias/Adam': [1], 'pred_net/layer_a_0/bias/Adam': [48], 'pred_net/layer_f_1/bias': [48], 'pred_net/Variable_5': [1, 196608], 'pred_net/layer_ahat_3/bias/Adam': [192], 'pred_net/layer_ahat_1/kernel': [3, 3, 48, 48], 'pred_net/Variable_6': [1, 98304], 'pred_net/Variable_2': [1, 98304], 'pred_net/layer_o_0/bias/Adam': [1], 'pred_net/layer_i_2/kernel/Adam_1': [3, 3, 480, 96], 'pred_net/layer_f_3/kernel': [3, 3, 576, 192], 'pred_net/layer_f_2/kernel': [3, 3, 480, 96], 'model_2_1/pred_net/Variable_11': [1, 98304], 'pred_net/layer_ahat_0/bias/Adam': [1], 'pred_net/Variable_11': [1, 98304], 'pred_net/layer_ahat_2/kernel': [3, 3, 96, 96], 'pred_net/layer_o_3/kernel': [3, 3, 576, 192], 'pred_net/layer_i_3/kernel/Adam': [3, 3, 576, 192], 'model_2/pred_net/Variable_2': [1, 98304], 'pred_net/Variable_10': [1, 196608], 'model_2_1/pred_net/Variable_2': [1, 98304], 'pred_net/Variable': [1, 16384], 'pred_net/layer_a_1/bias/Adam_1': [96], 'pred_net/Variable_1': [1, 196608], 'pred_net/layer_ahat_0/kernel/Adam_1': [3, 3, 1, 1], 'model_2_1/pred_net/Variable_6': [1, 98304], 'pred_net/layer_ahat_1/kernel/Adam': [3, 3, 48, 48], 'model_2_1/pred_net/Variable_8': [1, 32768], 'model_2_1/pred_net/Variable_5': [1, 196608], 'pred_net/layer_f_1/bias/Adam': [48], 'model_2/pred_net/Variable_4': [1, 16384], 'pred_net/layer_c_0/bias/Adam_1': [1], 'pred_net/layer_o_2/kernel': [3, 3, 480, 96], 'pred_net/layer_f_0/kernel': [3, 3, 51, 1], 'model_2_1/pred_net/Variable_7': [1, 49152], 'model_2/pred_net/Variable_11': [1, 98304], 'model_2/pred_net/Variable_10': [1, 196608], 'pred_net/layer_f_3/kernel/Adam': [3, 3, 576, 192], 'pred_net/layer_f_1/kernel/Adam_1': [3, 3, 240, 48], 'model_2/pred_net/Variable_1': [1, 196608], 'pred_net/layer_ahat_3/kernel/Adam': [3, 3, 192, 192], 'pred_net/layer_o_1/bias/Adam_1': [48], 'pred_net/layer_a_1/bias': [96], 'model_2_1/pred_net/Variable_10': [1, 196608], 'pred_net/Variable_8': [1, 32768], 'model_2/pred_net/Variable': [1, 16384], 'global_step': [], 'model_2/pred_net/Variable_7': [1, 49152], 'pred_net/layer_ahat_0/kernel': [3, 3, 1, 1], 'pred_net/layer_o_2/bias': [96], 'pred_net/layer_f_2/kernel/Adam_1': [3, 3, 480, 96], 'model_2_1/pred_net/Variable_1': [1, 196608], 'pred_net/layer_o_0/kernel/Adam_1': [3, 3, 51, 1], 'model_2/pred_net/Variable_5': [1, 196608], 'pred_net/layer_a_0/kernel/Adam_1': [3, 3, 2, 48], 'pred_net/layer_c_2/bias/Adam': [96], 'pred_net/layer_i_3/kernel/Adam_1': [3, 3, 576, 192], 'pred_net/layer_a_1/kernel/Adam_1': [3, 3, 96, 96], 'pred_net/layer_o_3/bias': [192], 'pred_net/Variable_9': [1, 393216], 'pred_net/layer_i_2/bias/Adam': [96], 'model_2/pred_net/Variable_8': [1, 32768], 'pred_net/layer_a_1/bias/Adam': [96], 'model_2_1/pred_net/Variable': [1, 16384], 'model_2_1/pred_net/Variable_9': [1, 393216], 'pred_net/Variable_7': [1, 49152], 'pred_net/Variable_3': [1, 49152], 'model_2_1/pred_net/Variable_3': [1, 49152], 'pred_net/layer_a_2/bias': [192], 'pred_net/layer_ahat_2/kernel/Adam_1': [3, 3, 96, 96], 'model_2_1/pred_net/Variable_4': [1, 16384], 'pred_net/layer_a_1/kernel/Adam': [3, 3, 96, 96], 'pred_net/layer_a_1/kernel': [3, 3, 96, 96], 'pred_net/layer_o_2/kernel/Adam': [3, 3, 480, 96], 'pred_net/layer_a_2/bias/Adam': [192], 'pred_net/layer_a_2/kernel': [3, 3, 192, 192], 'pred_net/layer_a_2/kernel/Adam_1': [3, 3, 192, 192], 'pred_net/layer_i_0/kernel/Adam': [3, 3, 51, 1], 'pred_net/layer_ahat_2/kernel/Adam': [3, 3, 96, 96], 'pred_net/layer_i_3/kernel': [3, 3, 576, 192], 'pred_net/layer_ahat_0/bias': [1], 'pred_net/layer_ahat_0/bias/Adam_1': [1], 'pred_net/layer_ahat_0/kernel/Adam': [3, 3, 1, 1], 'pred_net/layer_a_2/kernel/Adam': [3, 3, 192, 192], 'pred_net/layer_ahat_1/bias': [48], 'pred_net/layer_f_0/bias/Adam_1': [1], 'model_2/pred_net/Variable_6': [1, 98304], 'pred_net/layer_ahat_1/kernel/Adam_1': [3, 3, 48, 48], 'pred_net/layer_ahat_2/bias': [96], 'pred_net/layer_o_0/kernel/Adam': [3, 3, 51, 1], 'pred_net/layer_c_1/bias': [48], 'pred_net/layer_ahat_2/bias/Adam': [96], 'pred_net/layer_i_2/bias/Adam_1': [96], 'pred_net/layer_a_0/bias': [48], 'pred_net/layer_ahat_1/bias/Adam': [48], 'pred_net/layer_c_0/bias': [1], 'pred_net/layer_ahat_2/bias/Adam_1': [96], 'pred_net/layer_c_3/kernel': [3, 3, 576, 192], 'dense_5/bias': [1], 'pred_net/layer_ahat_3/bias': [192], 'pred_net/layer_f_1/kernel': [3, 3, 240, 48], 'model_2/pred_net/Variable_3': [1, 49152], 'pred_net/layer_c_1/kernel': [3, 3, 240, 48], 'pred_net/layer_ahat_3/bias/Adam_1': [192], 'pred_net/layer_i_1/kernel/Adam': [3, 3, 240, 48], 'pred_net/layer_a_2/bias/Adam_1': [192], 'pred_net/layer_c_1/kernel/Adam': [3, 3, 240, 48], 'pred_net/layer_a_0/bias/Adam_1': [48], 'pred_net/layer_ahat_3/kernel': [3, 3, 192, 192], 'dense_5/kernel': [10, 1], 'pred_net/layer_ahat_3/kernel/Adam_1': [3, 3, 192, 192], 'model_2/pred_net/Variable_9': [1, 393216], 'pred_net/layer_c_0/kernel': [3, 3, 51, 1], 'pred_net/layer_o_1/bias': [48], 'pred_net/layer_c_0/kernel/Adam': [3, 3, 51, 1], 'pred_net/layer_o_1/kernel/Adam': [3, 3, 240, 48], 'pred_net/layer_c_0/kernel/Adam_1': [3, 3, 51, 1], 'pred_net/layer_c_1/bias/Adam': [48], 'pred_net/layer_c_1/bias/Adam_1': [48], 'pred_net/layer_ahat_1/bias/Adam_1': [48], 'pred_net/layer_c_1/kernel/Adam_1': [3, 3, 240, 48], 'pred_net/layer_c_3/kernel/Adam': [3, 3, 576, 192], 'pred_net/layer_c_2/bias': [96], 'pred_net/layer_c_2/bias/Adam_1': [96]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-b0b9fb2ed6f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'PredNetCell'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPredNetCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PredNet'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPredNet\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mkeras_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1175\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_distribution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_distributed\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1318\u001b[0m         return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1319\u001b[0m                                                \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m                                                saving_listeners)\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m   def _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks,\n",
      "\u001b[0;32m~/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1326\u001b[0m       logging.info('Warm-starting with WarmStartSettings: %s' %\n\u001b[1;32m   1327\u001b[0m                    (self._warm_start_settings,))\n\u001b[0;32m-> 1328\u001b[0;31m       \u001b[0mwarm_starting_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warm_start_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow/python/training/warm_starting_util.py\u001b[0m in \u001b[0;36mwarm_start\u001b[0;34m(ckpt_to_initialize_from, vars_to_warm_start, var_name_to_vocab_info, var_name_to_prev_var_name)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m           \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0m_warm_start_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_to_initialize_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_var_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m   prev_var_name_not_used = set(\n",
      "\u001b[0;32m~/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow/python/training/warm_starting_util.py\u001b[0m in \u001b[0;36m_warm_start_var\u001b[0;34m(var, prev_ckpt, prev_tensor_name)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# Assume tensor name remains the same.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mprev_tensor_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_var_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0mcheckpoint_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_ckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mprev_tensor_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\u001b[0m in \u001b[0;36minit_from_checkpoint\u001b[0;34m(ckpt_dir_or_file, assignment_map)\u001b[0m\n\u001b[1;32m    182\u001b[0m   \"\"\"\n\u001b[1;32m    183\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cross_tower_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0m_init_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_dir_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massignment_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     distribution_strategy_context.get_tower_context().merge_call(\n",
      "\u001b[0;32m~/data/miniconda3/envs/tf-nightly-gpu/lib/python3.6/site-packages/tensorflow/python/training/checkpoint_utils.py\u001b[0m in \u001b[0;36m_init_from_checkpoint\u001b[0;34m(_, ckpt_dir_or_file, assignment_map)\u001b[0m\n\u001b[1;32m    214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtensor_name_in_ckpt\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariable_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         raise ValueError(\"Tensor %s is not found in %s checkpoint %s\" % (\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0mtensor_name_in_ckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_dir_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         ))\n\u001b[1;32m    218\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_is_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor tower_1/pred_net_1/Variable is not found in ../data/models/keras/keras_model.ckpt checkpoint {'training/TFOptimizer/beta2_power': [], 'training/TFOptimizer/beta1_power': [], 'time_distributed_2/kernel': [4, 1], 'pred_net/layer_o_3/kernel/Adam_1': [3, 3, 576, 192], 'pred_net/layer_o_3/kernel/Adam': [3, 3, 576, 192], 'pred_net/layer_o_3/bias/Adam_1': [192], 'pred_net/layer_o_3/bias/Adam': [192], 'pred_net/layer_o_2/kernel/Adam_1': [3, 3, 480, 96], 'pred_net/layer_o_2/bias/Adam_1': [96], 'pred_net/layer_o_1/kernel/Adam_1': [3, 3, 240, 48], 'pred_net/layer_o_1/kernel': [3, 3, 240, 48], 'pred_net/layer_o_1/bias/Adam': [48], 'pred_net/layer_o_0/kernel': [3, 3, 51, 1], 'pred_net/layer_o_0/bias': [1], 'pred_net/layer_i_3/bias/Adam_1': [192], 'pred_net/layer_o_2/bias/Adam': [96], 'pred_net/layer_i_3/bias': [192], 'pred_net/layer_i_2/kernel/Adam': [3, 3, 480, 96], 'pred_net/layer_i_2/kernel': [3, 3, 480, 96], 'pred_net/layer_i_2/bias': [96], 'pred_net/layer_i_1/kernel/Adam_1': [3, 3, 240, 48], 'pred_net/layer_i_1/kernel': [3, 3, 240, 48], 'pred_net/layer_i_1/bias/Adam_1': [48], 'pred_net/layer_i_1/bias/Adam': [48], 'pred_net/layer_i_1/bias': [48], 'pred_net/layer_i_0/kernel/Adam_1': [3, 3, 51, 1], 'pred_net/layer_i_3/bias/Adam': [192], 'pred_net/layer_i_0/kernel': [3, 3, 51, 1], 'pred_net/layer_i_0/bias/Adam_1': [1], 'pred_net/layer_i_0/bias': [1], 'pred_net/layer_o_0/bias/Adam_1': [1], 'pred_net/layer_f_3/bias/Adam_1': [192], 'pred_net/layer_f_3/bias': [192], 'pred_net/layer_f_2/kernel/Adam': [3, 3, 480, 96], 'pred_net/layer_f_2/bias/Adam_1': [96], 'pred_net/layer_f_2/bias/Adam': [96], 'pred_net/layer_f_2/bias': [96], 'pred_net/layer_f_3/kernel/Adam_1': [3, 3, 576, 192], 'pred_net/layer_f_1/kernel/Adam': [3, 3, 240, 48], 'pred_net/layer_f_1/bias/Adam_1': [48], 'pred_net/layer_f_0/kernel/Adam': [3, 3, 51, 1], 'pred_net/layer_f_0/bias/Adam': [1], 'pred_net/layer_f_0/bias': [1], 'pred_net/layer_i_0/bias/Adam': [1], 'pred_net/layer_c_3/kernel/Adam_1': [3, 3, 576, 192], 'pred_net/layer_c_3/bias/Adam_1': [192], 'pred_net/layer_c_3/bias/Adam': [192], 'pred_net/layer_c_3/bias': [192], 'pred_net/layer_c_2/kernel/Adam_1': [3, 3, 480, 96], 'pred_net/layer_c_2/kernel/Adam': [3, 3, 480, 96], 'pred_net/layer_f_0/kernel/Adam_1': [3, 3, 51, 1], 'pred_net/layer_c_2/kernel': [3, 3, 480, 96], 'pred_net/layer_f_3/bias/Adam': [192], 'pred_net/layer_a_0/kernel/Adam': [3, 3, 2, 48], 'pred_net/layer_a_0/kernel': [3, 3, 2, 48], 'time_distributed_2/bias': [1], 'pred_net/Variable_4': [1, 16384], 'pred_net/layer_c_0/bias/Adam': [1], 'pred_net/layer_a_0/bias/Adam': [48], 'pred_net/layer_f_1/bias': [48], 'pred_net/Variable_5': [1, 196608], 'pred_net/layer_ahat_3/bias/Adam': [192], 'pred_net/layer_ahat_1/kernel': [3, 3, 48, 48], 'pred_net/Variable_6': [1, 98304], 'pred_net/Variable_2': [1, 98304], 'pred_net/layer_o_0/bias/Adam': [1], 'pred_net/layer_i_2/kernel/Adam_1': [3, 3, 480, 96], 'pred_net/layer_f_3/kernel': [3, 3, 576, 192], 'pred_net/layer_f_2/kernel': [3, 3, 480, 96], 'model_2_1/pred_net/Variable_11': [1, 98304], 'pred_net/layer_ahat_0/bias/Adam': [1], 'pred_net/Variable_11': [1, 98304], 'pred_net/layer_ahat_2/kernel': [3, 3, 96, 96], 'pred_net/layer_o_3/kernel': [3, 3, 576, 192], 'pred_net/layer_i_3/kernel/Adam': [3, 3, 576, 192], 'model_2/pred_net/Variable_2': [1, 98304], 'pred_net/Variable_10': [1, 196608], 'model_2_1/pred_net/Variable_2': [1, 98304], 'pred_net/Variable': [1, 16384], 'pred_net/layer_a_1/bias/Adam_1': [96], 'pred_net/Variable_1': [1, 196608], 'pred_net/layer_ahat_0/kernel/Adam_1': [3, 3, 1, 1], 'model_2_1/pred_net/Variable_6': [1, 98304], 'pred_net/layer_ahat_1/kernel/Adam': [3, 3, 48, 48], 'model_2_1/pred_net/Variable_8': [1, 32768], 'model_2_1/pred_net/Variable_5': [1, 196608], 'pred_net/layer_f_1/bias/Adam': [48], 'model_2/pred_net/Variable_4': [1, 16384], 'pred_net/layer_c_0/bias/Adam_1': [1], 'pred_net/layer_o_2/kernel': [3, 3, 480, 96], 'pred_net/layer_f_0/kernel': [3, 3, 51, 1], 'model_2_1/pred_net/Variable_7': [1, 49152], 'model_2/pred_net/Variable_11': [1, 98304], 'model_2/pred_net/Variable_10': [1, 196608], 'pred_net/layer_f_3/kernel/Adam': [3, 3, 576, 192], 'pred_net/layer_f_1/kernel/Adam_1': [3, 3, 240, 48], 'model_2/pred_net/Variable_1': [1, 196608], 'pred_net/layer_ahat_3/kernel/Adam': [3, 3, 192, 192], 'pred_net/layer_o_1/bias/Adam_1': [48], 'pred_net/layer_a_1/bias': [96], 'model_2_1/pred_net/Variable_10': [1, 196608], 'pred_net/Variable_8': [1, 32768], 'model_2/pred_net/Variable': [1, 16384], 'global_step': [], 'model_2/pred_net/Variable_7': [1, 49152], 'pred_net/layer_ahat_0/kernel': [3, 3, 1, 1], 'pred_net/layer_o_2/bias': [96], 'pred_net/layer_f_2/kernel/Adam_1': [3, 3, 480, 96], 'model_2_1/pred_net/Variable_1': [1, 196608], 'pred_net/layer_o_0/kernel/Adam_1': [3, 3, 51, 1], 'model_2/pred_net/Variable_5': [1, 196608], 'pred_net/layer_a_0/kernel/Adam_1': [3, 3, 2, 48], 'pred_net/layer_c_2/bias/Adam': [96], 'pred_net/layer_i_3/kernel/Adam_1': [3, 3, 576, 192], 'pred_net/layer_a_1/kernel/Adam_1': [3, 3, 96, 96], 'pred_net/layer_o_3/bias': [192], 'pred_net/Variable_9': [1, 393216], 'pred_net/layer_i_2/bias/Adam': [96], 'model_2/pred_net/Variable_8': [1, 32768], 'pred_net/layer_a_1/bias/Adam': [96], 'model_2_1/pred_net/Variable': [1, 16384], 'model_2_1/pred_net/Variable_9': [1, 393216], 'pred_net/Variable_7': [1, 49152], 'pred_net/Variable_3': [1, 49152], 'model_2_1/pred_net/Variable_3': [1, 49152], 'pred_net/layer_a_2/bias': [192], 'pred_net/layer_ahat_2/kernel/Adam_1': [3, 3, 96, 96], 'model_2_1/pred_net/Variable_4': [1, 16384], 'pred_net/layer_a_1/kernel/Adam': [3, 3, 96, 96], 'pred_net/layer_a_1/kernel': [3, 3, 96, 96], 'pred_net/layer_o_2/kernel/Adam': [3, 3, 480, 96], 'pred_net/layer_a_2/bias/Adam': [192], 'pred_net/layer_a_2/kernel': [3, 3, 192, 192], 'pred_net/layer_a_2/kernel/Adam_1': [3, 3, 192, 192], 'pred_net/layer_i_0/kernel/Adam': [3, 3, 51, 1], 'pred_net/layer_ahat_2/kernel/Adam': [3, 3, 96, 96], 'pred_net/layer_i_3/kernel': [3, 3, 576, 192], 'pred_net/layer_ahat_0/bias': [1], 'pred_net/layer_ahat_0/bias/Adam_1': [1], 'pred_net/layer_ahat_0/kernel/Adam': [3, 3, 1, 1], 'pred_net/layer_a_2/kernel/Adam': [3, 3, 192, 192], 'pred_net/layer_ahat_1/bias': [48], 'pred_net/layer_f_0/bias/Adam_1': [1], 'model_2/pred_net/Variable_6': [1, 98304], 'pred_net/layer_ahat_1/kernel/Adam_1': [3, 3, 48, 48], 'pred_net/layer_ahat_2/bias': [96], 'pred_net/layer_o_0/kernel/Adam': [3, 3, 51, 1], 'pred_net/layer_c_1/bias': [48], 'pred_net/layer_ahat_2/bias/Adam': [96], 'pred_net/layer_i_2/bias/Adam_1': [96], 'pred_net/layer_a_0/bias': [48], 'pred_net/layer_ahat_1/bias/Adam': [48], 'pred_net/layer_c_0/bias': [1], 'pred_net/layer_ahat_2/bias/Adam_1': [96], 'pred_net/layer_c_3/kernel': [3, 3, 576, 192], 'dense_5/bias': [1], 'pred_net/layer_ahat_3/bias': [192], 'pred_net/layer_f_1/kernel': [3, 3, 240, 48], 'model_2/pred_net/Variable_3': [1, 49152], 'pred_net/layer_c_1/kernel': [3, 3, 240, 48], 'pred_net/layer_ahat_3/bias/Adam_1': [192], 'pred_net/layer_i_1/kernel/Adam': [3, 3, 240, 48], 'pred_net/layer_a_2/bias/Adam_1': [192], 'pred_net/layer_c_1/kernel/Adam': [3, 3, 240, 48], 'pred_net/layer_a_0/bias/Adam_1': [48], 'pred_net/layer_ahat_3/kernel': [3, 3, 192, 192], 'dense_5/kernel': [10, 1], 'pred_net/layer_ahat_3/kernel/Adam_1': [3, 3, 192, 192], 'model_2/pred_net/Variable_9': [1, 393216], 'pred_net/layer_c_0/kernel': [3, 3, 51, 1], 'pred_net/layer_o_1/bias': [48], 'pred_net/layer_c_0/kernel/Adam': [3, 3, 51, 1], 'pred_net/layer_o_1/kernel/Adam': [3, 3, 240, 48], 'pred_net/layer_c_0/kernel/Adam_1': [3, 3, 51, 1], 'pred_net/layer_c_1/bias/Adam': [48], 'pred_net/layer_c_1/bias/Adam_1': [48], 'pred_net/layer_ahat_1/bias/Adam_1': [48], 'pred_net/layer_c_1/kernel/Adam_1': [3, 3, 240, 48], 'pred_net/layer_c_3/kernel/Adam': [3, 3, 576, 192], 'pred_net/layer_c_2/bias': [96], 'pred_net/layer_c_2/bias/Adam_1': [96]}"
     ]
    }
   ],
   "source": [
    "with tf.keras.utils.CustomObjectScope({'PredNetCell': PredNetCell, 'PredNet': PredNet}):\n",
    "    keras_estimator.train(input_fn, steps=100, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
