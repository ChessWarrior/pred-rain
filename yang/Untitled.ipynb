{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twofyw/miniconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Processing subdirectory', max=705), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "%run cvt2tfrecord.py --records ../data/tfrecords/train_1 --data_dir ../data/SRAD2018_TRAIN_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_greyscale(fn):\n",
    "    \"\"\" Opens an image using OpenCV given the file path.\n",
    "\n",
    "    Arguments:\n",
    "        fn: the file path of the image\n",
    "\n",
    "    Returns:\n",
    "        The image in greyscale format as numpy array of floats normalized to range between 0.0 - 1.0\n",
    "    \"\"\"\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    if not os.path.exists(fn) and not str(fn).startswith(\"http\"):\n",
    "        raise OSError('No such file or directory: {}'.format(fn))\n",
    "    elif os.path.isdir(fn) and not str(fn).startswith(\"http\"):\n",
    "        raise OSError('Is a directory: {}'.format(fn))\n",
    "    else:\n",
    "        #res = np.array(Image.open(fn), dtype=np.float32)/255\n",
    "        #if len(res.shape)==2: res = np.repeat(res[...,None],3,2)\n",
    "        #return res\n",
    "        try:\n",
    "            if str(fn).startswith(\"http\"):\n",
    "                req = urllib.urlopen(str(fn))\n",
    "                image = np.asarray(bytearray(req.read()), dtype=\"uint8\")\n",
    "                im = cv2.imdecode(image, flags).astype(np.float32)/255\n",
    "            else:\n",
    "                im = cv2.imread(str(fn), flags).astype(np.float32)/255\n",
    "            if im is None: raise OSError(f'File not recognized by opencv: {fn}')\n",
    "            return im\n",
    "        except Exception as e:\n",
    "            raise OSError('Error handling image at: {}'.format(fn)) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = '../data/SRAD2018_TRAIN_001/RAD_206482464212530/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_std_subdir(subdir):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ims = np.asarray([open_greyscale(o) for o in Path(subdir).glob('**/*.png')])\n",
    "    mean, std = np.mean(ims), np.std(ims)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_dir = Path('../data/SRAD2018_TRAIN_001')\n",
    "subdirs = [o for o in par_dir.iterdir() if o.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "means, stds = zip(*[calc_mean_std_subdir(o) for o in subdirs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.9820557,\n",
       "  0.7564683,\n",
       "  0.968596,\n",
       "  0.9650422,\n",
       "  0.98231244,\n",
       "  0.7932429,\n",
       "  0.9655625,\n",
       "  0.97146374,\n",
       "  0.9070648,\n",
       "  0.7613075),\n",
       " (0.12885971,\n",
       "  0.3993739,\n",
       "  0.16909033,\n",
       "  0.17655694,\n",
       "  0.12847538,\n",
       "  0.39483172,\n",
       "  0.17846707,\n",
       "  0.16026804,\n",
       "  0.28292444,\n",
       "  0.41495243))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean , std = np.mean(stds), np.mean(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader import calc_mean_std_par_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0a578d6c7a4695a1c78b0f375fd1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=705), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean, std = calc_mean_std_par_dir('../data/SRAD2018_TRAIN_001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'stat.csv'\n",
    "with open(fn, 'w') as f:\n",
    "        np.array([mean, std]).tofile(f, ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27102503180503845,0.8787143230438232"
     ]
    }
   ],
   "source": [
    "!cat stat.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SequenceGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twofyw/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_train(serialized_example):\n",
    "    features, sequence_features = tf.parse_single_sequence_example(\n",
    "        serialized_example, context_features={\n",
    "            'time_stamp': tf.FixedLenFeature([], tf.string),\n",
    "        }, sequence_features={\n",
    "            \"raw_png\": tf.FixedLenSequenceFeature([], dtype=tf.string)\n",
    "        })\n",
    "    cast_to_float32 = partial(tf.cast, dtype=tf.float32)\n",
    "    \n",
    "    x = tf.map_fn(tf.image.decode_png, sequence_features['raw_png'], dtype=tf.uint8,\n",
    "                back_prop=False, swap_memory=False, infer_shape=False)\n",
    "    x = tf.map_fn(cast_to_float32, x, dtype=tf.float32,\n",
    "                back_prop=False, swap_memory=False, infer_shape=False)\n",
    "    x = tf.squeeze(x) / 255\n",
    "    return x, features['time_stamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = tf.placeholder(tf.string, name='tfrecords')\n",
    "training_filenames = '../data/tfrecords/train_1.tfrecords'\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(parser_train).repeat()\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "iterator.initializer.run({filenames: training_filenames})\n",
    "x, time_stamp = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        ...,\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ]],\n",
       "\n",
       "       [[1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        ...,\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ]],\n",
       "\n",
       "       [[1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        ...,\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.     , 1.     , 1.     , ..., 0.03137, 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 0.03137, 1.     , 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 1.     , 1.     ],\n",
       "        ...,\n",
       "        [0.03137, 0.03137, 0.03137, ..., 1.     , 1.     , 1.     ],\n",
       "        [0.03529, 0.03137, 0.02745, ..., 1.     , 1.     , 1.     ],\n",
       "        [0.03529, 0.03922, 0.03922, ..., 1.     , 1.     , 1.     ]],\n",
       "\n",
       "       [[1.     , 1.     , 1.     , ..., 0.03137, 0.03529, 0.03529],\n",
       "        [1.     , 1.     , 1.     , ..., 0.02353, 0.01176, 1.     ],\n",
       "        [1.     , 1.     , 1.     , ..., 1.     , 0.02353, 1.     ],\n",
       "        ...,\n",
       "        [0.03922, 0.03137, 0.04706, ..., 1.     , 1.     , 1.     ],\n",
       "        [0.03922, 0.04706, 0.02353, ..., 1.     , 1.     , 1.     ],\n",
       "        [0.03137, 0.03137, 0.03137, ..., 1.     , 1.     , 1.     ]],\n",
       "\n",
       "       [[1.     , 1.     , 1.     , ..., 0.03137, 0.02745, 0.02745],\n",
       "        [1.     , 1.     , 1.     , ..., 0.03137, 0.02745, 0.03137],\n",
       "        [1.     , 1.     , 1.     , ..., 0.03529, 0.02745, 0.03529],\n",
       "        ...,\n",
       "        [0.01961, 0.04314, 0.03922, ..., 1.     , 1.     , 1.     ],\n",
       "        [0.03529, 0.03922, 0.03922, ..., 1.     , 1.     , 1.     ],\n",
       "        [0.04314, 0.02353, 0.02353, ..., 1.     , 1.     , 1.     ]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.prefetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.prednet import PredNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels, im_height, im_width = (3, 128, 160)\n",
    "input_shape = (n_channels, im_height, im_width) if K.image_data_format() == 'channels_first' else (im_height, im_width, n_channels)\n",
    "stack_sizes = (n_channels, 48, 96, 192)\n",
    "R_stack_sizes = stack_sizes\n",
    "A_filt_sizes = (3, 3, 3)\n",
    "Ahat_filt_sizes = (3, 3, 3, 3)\n",
    "R_filt_sizes = (3, 3, 3, 3)\n",
    "prednet = PredNet(stack_sizes, R_stack_sizes,\n",
    "                  A_filt_sizes, Ahat_filt_sizes, R_filt_sizes,\n",
    "                  output_mode='error', return_sequences=True, cell=tf.contrib.rnn.LSTMCell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = 10\n",
    "inputs = keras.layers.Input(shape=(nt,) + input_shape)\n",
    "km = keras.Model(prednet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has never been called, thus its weights have not yet been created, so no summary can be displayed. Build the model first (e.g. by calling it on some data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-1da2631021e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1544\u001b[0m     \"\"\"\n\u001b[1;32m   1545\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m       raise ValueError('This model has never been called, thus its weights '\n\u001b[0m\u001b[1;32m   1547\u001b[0m                        \u001b[0;34m'have not yet been created, so no summary can be '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m                        \u001b[0;34m'displayed. Build the model first '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has never been called, thus its weights have not yet been created, so no summary can be displayed. Build the model first (e.g. by calling it on some data)."
     ]
    }
   ],
   "source": [
    "km.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
