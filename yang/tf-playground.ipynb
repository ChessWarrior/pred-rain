{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/jupyter\r\n"
     ]
    }
   ],
   "source": [
    "!which jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (61, 501, 501, 1)\n",
    "def parser_train(serialized_example):\n",
    "    features, sequence_features = tf.parse_single_sequence_example(\n",
    "        serialized_example, context_features={\n",
    "            'time_stamp': tf.FixedLenFeature([], tf.string),\n",
    "        }, sequence_features={\n",
    "            \"raw_png\": tf.FixedLenSequenceFeature([], dtype=tf.string)\n",
    "        })\n",
    "    \n",
    "    x = tf.map_fn(tf.image.decode_png, sequence_features['raw_png'], dtype=tf.uint8,\n",
    "                back_prop=False, swap_memory=False, infer_shape=False)\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x /= 255\n",
    "    x.set_shape(shape)\n",
    "    return x, features['time_stamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<utils.transforms.Scale object at 0x7fc90deec198>, <__main__.Slice object at 0x7fc90deec278>, <utils.transforms.Normalize object at 0x7fc90deec128>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.transforms import *\n",
    "\n",
    "sz = 128\n",
    "nt = 10\n",
    "stats = np.fromfile('stat.csv', sep=',')\n",
    "\n",
    "class Slice(Transform):\n",
    "    \"\"\" Return a slice of the images\n",
    "    \n",
    "    Arguments:\n",
    "    The same as the built-in function slice\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.slice = slice(*args, **kwargs)\n",
    "        super().__init__(TfmType.NO)\n",
    "        \n",
    "    def do_transform(self, x, is_y):\n",
    "        return x[self.slice]\n",
    "    \n",
    "aug_tfms = [Slice(nt)]\n",
    "tfm, _ = tfms_from_stats(stats, sz, aug_tfms=aug_tfms, crop_type=CropType.NO)\n",
    "tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 3\n",
    "\n",
    "filenames = tf.placeholder(tf.string, name='tfrecords')\n",
    "training_filenames = '../data/tfrecords/train_1.tfrecords'\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "dataset = dataset.map(parser_train).map(tfm).batch(bs).repeat()\n",
    "# dataset = dataset.prefetch()\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "iterator.initializer.run({filenames: training_filenames})\n",
    "x, time_stamp = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn(fn_pattern, mode=tf.esti)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
