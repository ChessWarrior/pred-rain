{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.imports import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # so the IDs match nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # \"0, 1\" for multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.transforms import *\n",
    "PATH = Path('../data')\n",
    "# sz = 128\n",
    "sz = 256\n",
    "nt = 10\n",
    "bs = 4\n",
    "MODEL_VERSION = 'prednet_' + str(sz) + '_1'\n",
    "\n",
    "num_gpus = 2\n",
    "\n",
    "class Slice(Transform):\n",
    "    \"\"\" Return a slice of the images\n",
    "    \n",
    "    Arguments:\n",
    "    The same as the built-in function slice\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.slice = slice(*args, **kwargs)\n",
    "        super().__init__(TfmType.NO)\n",
    "        \n",
    "    def do_transform(self, x, is_y):\n",
    "        return x[self.slice]\n",
    "\n",
    "aug_tfms = [Slice(nt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.prednet_refactored import PredNetCell, PredNet\n",
    "\n",
    "# n_channels, im_height, im_width = (3, 128, 160)\n",
    "n_channels, im_height, im_width = (1, sz, sz)\n",
    "input_shape = (im_height, im_width, n_channels)\n",
    "stack_sizes = (n_channels, 48, 96, 192)\n",
    "R_stack_sizes = stack_sizes\n",
    "A_filt_sizes = (3, 3, 3)\n",
    "Ahat_filt_sizes = (3, 3, 3, 3)\n",
    "R_filt_sizes = (3, 3, 3, 3)\n",
    "\n",
    "layer_loss_weights = np.array([1., 0., 0., 0.])  # weighting for each layer in final loss; \"L_0\" model:  [1, 0, 0, 0], \"L_all\": [1, 0.1, 0.1, 0.1]\n",
    "layer_loss_weights = np.expand_dims(layer_loss_weights, 1)\n",
    "time_loss_weights = 1./ (nt - 1) * np.ones((nt,1))  # equally weight all timesteps except the first\n",
    "time_loss_weights[0] = 0\n",
    "\n",
    "prednet_cell = PredNetCell(stack_sizes=stack_sizes,\n",
    "                    R_stack_sizes=R_stack_sizes,\n",
    "                    A_filt_sizes=A_filt_sizes,\n",
    "                    Ahat_filt_sizes=Ahat_filt_sizes,\n",
    "                    R_filt_sizes=R_filt_sizes)\n",
    "\n",
    "prednet = PredNet(prednet_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(nt,) + input_shape)\n",
    "errors = prednet(inputs)  # errors will be (batch_size, nt, nb_layers)\n",
    "errors_by_time = TimeDistributed(Dense(1, trainable=False), weights=[layer_loss_weights, np.zeros(1)], trainable=False)(errors)  # calculate weighted error by layer\n",
    "errors_by_time = Flatten()(errors_by_time)  # will be (batch_size, nt)\n",
    "final_errors = Dense(1, weights=[time_loss_weights, np.zeros(1)], trainable=False)(errors_by_time)  # weight errors by time\n",
    "model = Model(inputs=inputs, outputs=final_errors)\n",
    "# model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "# model = tf.keras.utils.multi_gpu_model(model, gpus=num_gpus)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "# model.compile(loss='mean_absolute_error', optimizer=tf.train.AdamOptimizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10, 128, 128, 1)   0         \n",
      "_________________________________________________________________\n",
      "pred_net (PredNet)           (None, 10, 4)             6909818   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 10, 1)             5         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 6,909,834\n",
      "Trainable params: 6,909,818\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 10, 256, 256, 1)   0         \n",
      "_________________________________________________________________\n",
      "pred_net_2 (PredNet)         (None, 10, 4)             6909818   \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 10, 1)             5         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 6,909,834\n",
      "Trainable params: 6,909,818\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(fns = ['../data/tfrecords/train_1.tfrecords'],\n",
    "             sz=128, nt=10, aug_tfms=aug_tfms,\n",
    "             stats_fn='stat.csv', stats_sep=','):\n",
    "    dataset = tf.data.TFRecordDataset(fns)\n",
    "    \n",
    "    y = tf.zeros([bs, 1])\n",
    "    def parser_train(serialized_example):\n",
    "        # experimental. TODO: read only needed samples\n",
    "        shape = (61, 501, 501, 3)\n",
    "        context_features = {\n",
    "                'time_stamp': tf.FixedLenFeature([], tf.string),\n",
    "            }\n",
    "        sequence_features = {\n",
    "                \"raw_png\": tf.FixedLenSequenceFeature([], dtype=tf.string)\n",
    "            }\n",
    "        \n",
    "        features, sequence_features = tf.parse_single_sequence_example(\n",
    "            serialized_example, \n",
    "            context_features=context_features, \n",
    "            sequence_features=sequence_features)\n",
    "\n",
    "        x = tf.map_fn(tf.image.decode_png, sequence_features['raw_png'], dtype=tf.uint8,\n",
    "                    back_prop=False, swap_memory=False, infer_shape=False)\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x /= 255\n",
    "        x.set_shape(shape)\n",
    "        x = tf.expand_dims(x[:,:,:,0], axis=3)\n",
    "        return x, y\n",
    "    \n",
    "    stats = np.fromfile(stats_fn, sep=stats_sep)\n",
    "    tfms, _ = tfms_from_stats(stats, sz, aug_tfms=aug_tfms, crop_type=CropType.NO)\n",
    "    \n",
    "    dataset = dataset.map(parser_train)\n",
    "    dataset = dataset.map(tfms)\n",
    "    dataset = dataset.batch(bs)\n",
    "    dataset = dataset.repeat()\n",
    "    # dataset = dataset.prefetch()\n",
    "    \n",
    "#     return dataset\n",
    "    \n",
    "    y = tf.zeros([bs, 1])\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    x, _ = iterator.get_next()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(write_grads=True, write_images=True),\n",
    "    keras.callbacks.History(),\n",
    "    keras.callbacks.ModelCheckpoint(),\n",
    "    keras.callbacks.EarlyStopping()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.3351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f58385499b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, steps_per_epoch=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = {'PredNetCell': PredNetCell, 'PredNet': PredNet}\n",
    "model = tf.keras.models.load_model('keras', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = PATH/'models'/\n",
    "if not weights_path.exists: weights_path.mkdir()\n",
    "model.save_weights(str(weights_path/MODEL_VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'pred_net_2/layer_a_0/kernel:0' shape=(3, 3, 2, 48) dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
